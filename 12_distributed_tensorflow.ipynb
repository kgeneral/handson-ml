{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.6\n",
      "IPython 6.4.0\n",
      "\n",
      "numpy 1.14.5\n",
      "sklearn 0.19.1\n",
      "scipy 1.1.0\n",
      "matplotlib 2.2.2\n",
      "tensorflow 1.9.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p numpy,sklearn,scipy,matplotlib,tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***12장 – 분산 텐서플로***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "목적\n",
    "- 대규모 NN 을 여러 장치에 병렬 / 분산 실행하여 수행 시간을 절약한다.\n",
    "\n",
    "Tensorflow 분산 처리의 장점\n",
    "- 계산 그래프의 여러 장치 / 머신 분할방법 제어 가능\n",
    "- 다양한 방식의 연산 병렬화 및 동기화 가능\n",
    "\n",
    "병렬 수행의 실사례\n",
    "- 신경망 병렬 수행\n",
    "- 모델 세밀 튜닝을 위해 큰 하이퍼파라미터 공간을 탐색\n",
    "- 대규모 NN 의 앙상블 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12.1 단일 머신의 다중 장치**\n",
    "\n",
    "- 단일 머신에 GPU 추가\n",
    "- 다중 머신의 경우 네트워크 비용으로 인해 더 비효율적일 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*12.1.1 설치*\n",
    "\n",
    "- 그래픽 카드 호환성 확인 : https://developer.nvidia.com/cuda-gpus\n",
    "- CUDA : gpu 를 통한 명시적 computing 을 가능하게 하는 library\n",
    "- cuDNN : DNN 을 위한 기초적 GPU 가속 library\n",
    "-- activation function, normalize, forward / back propagation, pooling 등\n",
    "- CUDA, cuDNN 바이너리 다운로드시 nvidia 개발자 계정이 필요 (https://developer.nvidia.com/)\n",
    "\n",
    "* 본 실습에서는 gcp 를 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pyenv, anaconda 등 가상 환경을 사용하고 잇다면 적절한 환경으로 활성화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬 2와 3을 모두 지원합니다. 공통 모듈을 임포트하고 맷플롯립 그림이 노트북 안에 포함되도록 설정하고 생성한 그림을 저장하기 위한 함수를 준비합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 2와 파이썬 3 지원\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# 공통\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 일관된 출력을 위해 유사난수 초기화\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# 맷플롯립 설정\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# 그림을 저장할 폴더\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"distributed\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로컬 서버"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.constant(\"Hello distributed TensorFlow!\")\n",
    "server = tf.train.Server.create_local_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello distributed TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(server.target) as sess:\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- gpu 초기화 및 정보 로그가 나온다면 성공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*12.1.2 GPU RAM 관리*\n",
    "\n",
    "- 단일 GPU 에 여러 프로그램 수행시 경우에 따라 OOM 발생할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 별도 GPU 에 각각 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUDA_VISIBLE_DEVICES=0,1 python3 code.py - 복수 device ID 지정시 multi gpu 로 구동되는지 확인\n",
    "#CUDA_VISIBLE_DEVICES=\"\" 의 경우 CPU 로 수행됨\n",
    "\n",
    "# https://stackoverflow.com/questions/37893755/tensorflow-set-cuda-visible-devices-within-jupyter\n",
    "# http://dongjinlee.tistory.com/entry/%EC%84%A0%ED%83%9D%ED%95%9C-GPU%EC%97%90%EB%A7%8C-%EB%A9%94%EB%AA%A8%EB%A6%AC-%ED%95%A0%EB%8B%B9%ED%95%98%EB%8A%94-%EB%B0%A9%EB%B2%95\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "# do some tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. GPU 메모리 일부만을 사용하도록 강제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.configProto();\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "session = tf.session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 필요할 때 메모리를 확장 할당하는 옵션 활용\n",
    "- 비활용 메모리 반납에 시간이 소요되므로(memory fragmentation 을 피하기 위해) 효용성이 낮음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.configProto();\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*12.1.3 장치에 연산 배치하기*\n",
    "\n",
    "dynamic placer\n",
    "- 사용자 지정 배치 규칙에 비해 좋은 효율성을 보이고 있지 않다고 함.\n",
    "- G사 내부용으로 현재 오픈소스화 되어 잇지 않음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. simple placer\n",
    "- computation graph 수행시 device 에 배치되지 않는 node 를 평가할 때 사용\n",
    "\n",
    "분배 규칙\n",
    "- node 가 이미 배치되어 있는 장비는 해당 node를 그대로 둠\n",
    "- 사용자가 node 를 어떤 장치에 할당햇다면 placer 가 node 를 배치\n",
    "- GPU #0 이 기본, GPU 가 소진되면 CPU 로 전환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 배치 로깅\n",
    "- placer 가 node 를 배치할 시점에 메세지를 기록하는 옵션\n",
    "- TODO : 출력되는 log 에 대한 부연 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    a = tf.Variable(3.0)\n",
    "    b = tf.constant(4.0)\n",
    "\n",
    "c = a * b\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "session = tf.session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.initializer.run(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 동적 배치 함수\n",
    "\n",
    "- tf.device 파라미터로 함수를 넣을 수 있음\n",
    "- 실무에서 자주 사용 되나요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variables_on_cpu(op):\n",
    "    if(op.type == \"Variable\"):\n",
    "        return \"/cpu:0\"\n",
    "    else:\n",
    "        return \"/gpu:0\"\n",
    "\n",
    "with tf.device(variables_on_cpu):\n",
    "    a = tf.Variable(3.0)\n",
    "    b = tf.constant(4.0)\n",
    "    c = a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 연산과 커널\n",
    "\n",
    "- CPU, GPU 장치별로 지원가능한 연산이 구분되어 잇음\n",
    "- 커널 : 장치에 맞는 구현\n",
    "- 예) integer Variable 은 GPU 에서 지원하지 않음 - 효율성 문제로 강제 미지원\n",
    "- 하시 예시의 경우, dtype=tf.float32 로 명시하지 않으면 숫자 notation 을 통해 정수로 임의판단함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    a = tf.Variable(3) \n",
    "    \n",
    "session.run(i.initializer) # error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 간접 배치\n",
    "\n",
    "- 해당 커널이 없는 device 에 할당된 연산을, 해당 커널을 가진 임의 device 에 할당하는 옵션\n",
    "- 묵시적 할당이라 프로그래머 예측을 벗어나는 위험이 잇어보이는데...\n",
    "- GPU 가 없을때 CPU 가 지원안하는 커널인 연산을 입력하면? (그런게 잇나?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    a = tf.Variable(3)\n",
    "    \n",
    "config = tf.ConfigProto()\n",
    "config.allow_soft_placement = True\n",
    "session = tf.session(config=config)\n",
    "session.run(i.initializer) # /cpu:0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*12.1.4 병렬 실행*\n",
    "\n",
    "CPU\n",
    "1) queueing\n",
    "- nn graph 실행시, 먼저 평가할 연산을 찾은 뒤 관련 연산들의 의존도를 측정\n",
    "- 의존성이 전혀 없는 node 들을 할당된 장치의 evaluation queue 에 추가\n",
    "- 하나의 연산이 평가되면 다른 모든 연산의 dependency counter 가 감소\n",
    "- 그 후 dependency counter 가 0 이 되는 연산이 추가로 장치의 evaluation queue 에 추가\n",
    "- 필요한 모든 Node 가 평가되면 output 을 return\n",
    "2) pooling\n",
    "- cpu 의 evaluation queue 에 있는 연산은 inter-op thread pool 로 이동\n",
    "- 각 상황에 맞도록 병렬 처리  \n",
    "-- multi-core hardware 를 이용\n",
    "-- multithread cpu 커널 \n",
    "--- 여러개의 부분연산으로 분리하여 다른 evaluation queue 에 배치\n",
    "--- 상기 evaluation queue 에 배치된 연산은 (모든 multithread cpu 커널이 공유하는)intra-op thread pool 로 이동\n",
    "\n",
    "- inter / intra-op thread pool 의 thread 수는 옵션으로 조정가능 - default 0 (모든 코어 사용)\n",
    "-- 현재 CPU 특정 코어 지정이 불가하기 때문에, 옵션값을 CPU 코어 수 보다 적에 부여해야함\n",
    "\n",
    "GPU\n",
    "- GPU 상의 evaluation queue 연산들은 순서대로 평가됨\n",
    "- 대다수의 연산에 대한 CUDA / cuDNN 기반 multithread GPU 커널 존재\n",
    "\n",
    "\n",
    "* 그림 12-5 삽입 및 관련 설명 추가\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*12.1.5 제어 의존성*\n",
    "\n",
    "- 의존 연산이 모두 수행되엇음에도, 효율을 위해 evaluation 을 가급적 delay 할 경우\n",
    "-- 다량의 메모리 점유, 다수의 external I/O 발생 등\n",
    "- 다른 연산을 병렬 처리 하며 순차적 실행\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(1.0)\n",
    "b = a + 2.0\n",
    "\n",
    "with tf.control_dependencies([a,b]):\n",
    "    x = tf.constant(3.0)\n",
    "    y = tf.constant(4.0)\n",
    "    \n",
    "z = x + y # z 도 a, b 의 evaluation 을 기다리는 의존성이 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12.2 다중 머신의 다중 장치**\n",
    "\n",
    "- task : 하나 이상의 텐서플로 서버로 구성\n",
    "- job : 각기 이름이 부여된 task group\n",
    "- cluster : task 라고 불리는 하나 이상의 텐서플로 서버로 구성\n",
    "\n",
    "\n",
    "* 그림 12-6 추가 및 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 클러스터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_spec = tf.train.ClusterSpec({\n",
    "    \"ps\": [\n",
    "        \"127.0.0.1:2221\",  # /job:ps/task:0\n",
    "        \"127.0.0.1:2222\",  # /job:ps/task:1\n",
    "    ],\n",
    "    \"worker\": [\n",
    "        \"127.0.0.1:2223\",  # /job:worker/task:0 # 외부 장비 ip 로 교체\n",
    "        \"127.0.0.1:2224\",  # /job:worker/task:1\n",
    "        \"127.0.0.1:2225\",  # /job:worker/task:2\n",
    "    ]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동일 머신에서 여러 task 수행은 가능하나 비추천. 각 GPU RAM 점유를 수동으로 조정해줘야함\n",
    "task_ps0 = tf.train.Server(cluster_spec, job_name=\"ps\", task_index=0)\n",
    "task_ps1 = tf.train.Server(cluster_spec, job_name=\"ps\", task_index=1)\n",
    "task_worker0 = tf.train.Server(cluster_spec, job_name=\"worker\", task_index=0)\n",
    "task_worker1 = tf.train.Server(cluster_spec, job_name=\"worker\", task_index=1)\n",
    "task_worker2 = tf.train.Server(cluster_spec, job_name=\"worker\", task_index=2)\n",
    "\n",
    "# cluster task 설정 시 CUDA_VISIBLE_DEVICES 를 구분지어 설정할 수 있는가?\n",
    "#server.join() ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*12.2.1 세션 열기*\n",
    "\n",
    "- 모든 task 가 시작되면 특정 머신의 프로세스의 클라이언트에서 다른 모든 서버에 대해 세션을 열 수 있음\n",
    "- 하기 예시에서, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(1.0)\n",
    "b = a + 2\n",
    "c = a * 3\n",
    "\n",
    "# 해당 원격 텐서플로 서버에 대한 세션을 오픈, c 를 evaluate 하라는 명령을 전달\n",
    "# 해당 외부 장비의 기본장치(GPU) 에 배치 후 수행, 결과 반환\n",
    "with tf.Session(\"grpc://127.0.0.1:2223\") as sess: # 외부 장비 ip 로 교체\n",
    "    print(c.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*12.2.2 마스터와 워커 서비스*\n",
    "\n",
    "- Client / Server 는 gRPC 로 통신함\n",
    "-- 적절한 통신 포트를 방화벽에서 열어주어야 함\n",
    "- 텐서플로 서버는 기본적으로 마스터, 워커 서비스를 제공함\n",
    "-- 마스터 : 클라이언트가 세션을 열고 그래플르 실행할 수 잇게 해줌\n",
    "-- 워커 : 하나의 서버에서 graph 실행을 담당하는 RPC 서비스\n",
    "    \n",
    "- 유연성 제공\n",
    "- 1 Client 가 n Server 에 접속하는 각각 session 오픈 가능\n",
    "- task 마다 1 client 실행\n",
    "- 1 client 로 여러 task 제어\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*12.2.3 여러 태스크에 연산 할당하기*\n",
    "\n",
    "- job 이름, task 번호, 장치 유형/번호 지정하여 연산 할당 가능\n",
    "- 장치 유형/번호가 지정되지 않으면 해당 task 의 기본 장치 사용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여러 디바이스와 서버에 연산을 할당하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "with tf.device(\"/job:ps\"):\n",
    "    a = tf.Variable(1.0, name=\"a\")\n",
    "\n",
    "with tf.device(\"/job:worker\"):\n",
    "    b = a + 2\n",
    "\n",
    "with tf.device(\"/job:worker/task:1\"):\n",
    "    c = a + b\n",
    "    \n",
    "with tf.device(\"/job:ps/task:1/cpu:0\"):\n",
    "    d = a + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(\"grpc://127.0.0.1:2221\") as sess:\n",
    "    sess.run(a.initializer)\n",
    "    print(c.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*12.2.4 여러 대의 파라미터 서버에 변수를 나누어 분산하기*\n",
    "\n",
    "- 다량의 파라미터가 있는 대규모 모델의 경우, 서버 한 대로 IO가 몰리지 않게 여러 서버에 분산해둠\n",
    "- 별도 명시설정없이 모든 task 에 round-robin 할당해주는 방법 제공\n",
    "- 대체로 파라미터 서버는 파라미터 저장 / 송수신 용도로 사용되고 무거운 연산을 수행하지 않게 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "with tf.device(tf.train.replica_device_setter( # cluster=cluster_spec 처럼 클러스터 명세를 전달해도 ps_tasks 를 찾아서 이용함\n",
    "        ps_tasks=2,\n",
    "        ps_device=\"/job:ps\",\n",
    "        worker_device=\"/job:worker\")):\n",
    "    v1 = tf.Variable(1.0, name=\"v1\")  # /job:ps/task:0 (defaults to /cpu:0) 에 할당\n",
    "    v2 = tf.Variable(2.0, name=\"v2\")  # /job:ps/task:1 (defaults to /cpu:0) 에 할당\n",
    "    v3 = tf.Variable(3.0, name=\"v3\")  # /job:ps/task:0 (defaults to /cpu:0) 에 할당\n",
    "    s = v1 + v2            # /job:worker (defaults to task:0/cpu:0) 에 할당\n",
    "    with tf.device(\"/task:1\"):\n",
    "        p1 = 2 * s         # /job:worker/task:1 (defaults to /cpu:0) 에 할당\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            p2 = 3 * s     # /job:worker/task:1/cpu:0 에 할당\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "\n",
    "with tf.Session(\"grpc://127.0.0.1:2221\", config=config) as sess:\n",
    "    v1.initializer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*12.2.5 리소스 컨테이너를 사용해 여러 세션에서 상태 공유하기*\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 리더 (Reader) - 예전 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 6, 44]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "default1 = tf.constant([5.])\n",
    "default2 = tf.constant([6])\n",
    "default3 = tf.constant([7])\n",
    "dec = tf.decode_csv(tf.constant(\"1.,,44\"),\n",
    "                    record_defaults=[default1, default2, default3])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(dec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "더 이상 읽을 파일이 없습니다\n",
      "[array([[ 4.,  5.],\n",
      "       [ 1., -1.]], dtype=float32), array([1, 0], dtype=int32)]\n",
      "[array([[7., 8.]], dtype=float32), array([0], dtype=int32)]\n",
      "더 이상 훈련 샘플이 없습니다\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "test_csv = open(\"my_test.csv\", \"w\")\n",
    "test_csv.write(\"x1, x2 , target\\n\")\n",
    "test_csv.write(\"1.,, 0\\n\")\n",
    "test_csv.write(\"4., 5. , 1\\n\")\n",
    "test_csv.write(\"7., 8. , 0\\n\")\n",
    "test_csv.close()\n",
    "\n",
    "filename_queue = tf.FIFOQueue(capacity=10, dtypes=[tf.string], shapes=[()])\n",
    "filename = tf.placeholder(tf.string)\n",
    "enqueue_filename = filename_queue.enqueue([filename])\n",
    "close_filename_queue = filename_queue.close()\n",
    "\n",
    "reader = tf.TextLineReader(skip_header_lines=1)\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "x1, x2, target = tf.decode_csv(value, record_defaults=[[-1.], [-1.], [-1]])\n",
    "features = tf.stack([x1, x2])\n",
    "\n",
    "instance_queue = tf.RandomShuffleQueue(\n",
    "    capacity=10, min_after_dequeue=2,\n",
    "    dtypes=[tf.float32, tf.int32], shapes=[[2],[]],\n",
    "    name=\"instance_q\", shared_name=\"shared_instance_q\")\n",
    "enqueue_instance = instance_queue.enqueue([features, target])\n",
    "close_instance_queue = instance_queue.close()\n",
    "\n",
    "minibatch_instances, minibatch_targets = instance_queue.dequeue_up_to(2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(enqueue_filename, feed_dict={filename: \"my_test.csv\"})\n",
    "    sess.run(close_filename_queue)\n",
    "    try:\n",
    "        while True:\n",
    "            sess.run(enqueue_instance)\n",
    "    except tf.errors.OutOfRangeError as ex:\n",
    "        print(\"더 이상 읽을 파일이 없습니다\")\n",
    "    sess.run(close_instance_queue)\n",
    "    try:\n",
    "        while True:\n",
    "            print(sess.run([minibatch_instances, minibatch_targets]))\n",
    "    except tf.errors.OutOfRangeError as ex:\n",
    "        print(\"더 이상 훈련 샘플이 없습니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coord = tf.train.Coordinator()\n",
    "#threads = tf.train.start_queue_runners(coord=coord)\n",
    "#filename_queue = tf.train.string_input_producer([\"test.csv\"])\n",
    "#coord.request_stop()\n",
    "#coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QueueRunner와 Coordinator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 7.,  8.],\n",
      "       [ 1., -1.]], dtype=float32), array([0, 0], dtype=int32)]\n",
      "[array([[4., 5.]], dtype=float32), array([1], dtype=int32)]\n",
      "더 이상 훈련 샘플이 없습니다\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "filename_queue = tf.FIFOQueue(capacity=10, dtypes=[tf.string], shapes=[()])\n",
    "filename = tf.placeholder(tf.string)\n",
    "enqueue_filename = filename_queue.enqueue([filename])\n",
    "close_filename_queue = filename_queue.close()\n",
    "\n",
    "reader = tf.TextLineReader(skip_header_lines=1)\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "x1, x2, target = tf.decode_csv(value, record_defaults=[[-1.], [-1.], [-1]])\n",
    "features = tf.stack([x1, x2])\n",
    "\n",
    "instance_queue = tf.RandomShuffleQueue(\n",
    "    capacity=10, min_after_dequeue=2,\n",
    "    dtypes=[tf.float32, tf.int32], shapes=[[2],[]],\n",
    "    name=\"instance_q\", shared_name=\"shared_instance_q\")\n",
    "enqueue_instance = instance_queue.enqueue([features, target])\n",
    "close_instance_queue = instance_queue.close()\n",
    "\n",
    "minibatch_instances, minibatch_targets = instance_queue.dequeue_up_to(2)\n",
    "\n",
    "n_threads = 5\n",
    "queue_runner = tf.train.QueueRunner(instance_queue, [enqueue_instance] * n_threads)\n",
    "coord = tf.train.Coordinator()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(enqueue_filename, feed_dict={filename: \"my_test.csv\"})\n",
    "    sess.run(close_filename_queue)\n",
    "    enqueue_threads = queue_runner.create_threads(sess, coord=coord, start=True)\n",
    "    try:\n",
    "        while True:\n",
    "            print(sess.run([minibatch_instances, minibatch_targets]))\n",
    "    except tf.errors.OutOfRangeError as ex:\n",
    "        print(\"더 이상 훈련 샘플이 없습니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 4.,  5.],\n",
      "       [ 1., -1.]], dtype=float32), array([1, 0], dtype=int32)]\n",
      "[array([[7., 8.]], dtype=float32), array([0], dtype=int32)]\n",
      "더 이상 훈련 샘플이 없습니다\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "def read_and_push_instance(filename_queue, instance_queue):\n",
    "    reader = tf.TextLineReader(skip_header_lines=1)\n",
    "    key, value = reader.read(filename_queue)\n",
    "    x1, x2, target = tf.decode_csv(value, record_defaults=[[-1.], [-1.], [-1]])\n",
    "    features = tf.stack([x1, x2])\n",
    "    enqueue_instance = instance_queue.enqueue([features, target])\n",
    "    return enqueue_instance\n",
    "\n",
    "filename_queue = tf.FIFOQueue(capacity=10, dtypes=[tf.string], shapes=[()])\n",
    "filename = tf.placeholder(tf.string)\n",
    "enqueue_filename = filename_queue.enqueue([filename])\n",
    "close_filename_queue = filename_queue.close()\n",
    "\n",
    "instance_queue = tf.RandomShuffleQueue(\n",
    "    capacity=10, min_after_dequeue=2,\n",
    "    dtypes=[tf.float32, tf.int32], shapes=[[2],[]],\n",
    "    name=\"instance_q\", shared_name=\"shared_instance_q\")\n",
    "\n",
    "minibatch_instances, minibatch_targets = instance_queue.dequeue_up_to(2)\n",
    "\n",
    "read_and_enqueue_ops = [read_and_push_instance(filename_queue, instance_queue) for i in range(5)]\n",
    "queue_runner = tf.train.QueueRunner(instance_queue, read_and_enqueue_ops)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(enqueue_filename, feed_dict={filename: \"my_test.csv\"})\n",
    "    sess.run(close_filename_queue)\n",
    "    coord = tf.train.Coordinator()\n",
    "    enqueue_threads = queue_runner.create_threads(sess, coord=coord, start=True)\n",
    "    try:\n",
    "        while True:\n",
    "            print(sess.run([minibatch_instances, minibatch_targets]))\n",
    "    except tf.errors.OutOfRangeError as ex:\n",
    "        print(\"더 이상 훈련 샘플이 없습니다\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 타임아웃 지정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "6.0\n",
      "3.0\n",
      "4.0\n",
      "dequeue 타임 아웃\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "q = tf.FIFOQueue(capacity=10, dtypes=[tf.float32], shapes=[()])\n",
    "v = tf.placeholder(tf.float32)\n",
    "enqueue = q.enqueue([v])\n",
    "dequeue = q.dequeue()\n",
    "output = dequeue + 1\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.operation_timeout_in_ms = 1000\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(enqueue, feed_dict={v: 1.0})\n",
    "    sess.run(enqueue, feed_dict={v: 2.0})\n",
    "    sess.run(enqueue, feed_dict={v: 3.0})\n",
    "    print(sess.run(output))\n",
    "    print(sess.run(output, feed_dict={dequeue: 5}))\n",
    "    print(sess.run(output))\n",
    "    print(sess.run(output))\n",
    "    try:\n",
    "        print(sess.run(output))\n",
    "    except tf.errors.DeadlineExceededError as ex:\n",
    "        print(\"dequeue 타임 아웃\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로 1.4에서 소개된 Data API를 사용하면 손쉽게 데이터를 효율적으로 읽을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0에서 9까지 정수를 세 번 반복한 간단한 데이터셋을 일곱 개씩 배치로 만들어 시작해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(np.arange(10))\n",
    "dataset = dataset.repeat(3).batch(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 줄은 0에서 9까지 정수를 담은 데이터셋을 만듭니다. 두 번째 줄은 이 데이터셋의 원소를 세 번 반복하고 일곱 개씩 담은 새로운 데이터셋을 만듭니다. 위에서 볼 수 있듯이 원본 데이터셋에서 여러 변환 메서드를 연결하여 호출하여 적용했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그다음, 데이터셋을 한 번 순회하는 원-샷-이터레이터(one-shot-iterator)를 만들고, 다음 원소를 지칭하는 텐서를 얻기 위해 `get_next()` 메서드를 호출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`next_element`를 반복적으로 평가해서 데이터셋을 순회해 보죠. 원소가 별로 없기 때문에 `OutOfRangeError`가 발생합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6]\n",
      "[7 8 9 0 1 2 3]\n",
      "[4 5 6 7 8 9 0]\n",
      "[1 2 3 4 5 6 7]\n",
      "[8 9]\n",
      "완료\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while True:\n",
    "            print(next_element.eval())\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print(\"완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "좋네요! 잘 작동합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "늘 그렇듯이 텐서는 그래프를 실행(`sess.run()`)할 때마다 한 번만 평가된다는 것을 기억하세요. `next_element`에 의존하는 텐서를 여러개 평가하더라도 한 번만 평가됩니다. 또한 `next_element`를 동시에 두 번 실행해도 마찬가지입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 1, 2, 3, 4, 5, 6]), array([0, 1, 2, 3, 4, 5, 6])]\n",
      "[array([7, 8, 9, 0, 1, 2, 3]), array([7, 8, 9, 0, 1, 2, 3])]\n",
      "[array([4, 5, 6, 7, 8, 9, 0]), array([4, 5, 6, 7, 8, 9, 0])]\n",
      "[array([1, 2, 3, 4, 5, 6, 7]), array([1, 2, 3, 4, 5, 6, 7])]\n",
      "[array([8, 9]), array([8, 9])]\n",
      "완료\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while True:\n",
    "            print(sess.run([next_element, next_element]))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print(\"완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`interleave()` 메서드는 강력하지만 처음에는 이해하기 좀 어렵습니다. 예제를 통해 이해하는 것이 가장 좋습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(np.arange(10))\n",
    "dataset = dataset.repeat(3).batch(7)\n",
    "dataset = dataset.interleave(\n",
    "    lambda v: tf.data.Dataset.from_tensor_slices(v),\n",
    "    cycle_length=3,\n",
    "    block_length=2)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1,7,8,4,5,2,3,9,0,6,7,4,5,1,2,8,9,6,3,0,1,2,8,9,3,4,5,6,7,완료\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while True:\n",
    "            print(next_element.eval(), end=\",\")\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print(\"완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cycle_length=3`이므로 새로운 데이터셋은 이전 데이터셋에서 세 개의 원소를 추출합니다. 즉 `[0,1,2,3,4,5,6]`, `[7,8,9,0,1,2,3]`, `[4,5,6,7,8,9,0]` 입니다. 그다음 원소마다 하나의 데이터셋을 만들기 위해 람다(lambda) 함수를 호출합니다. `Dataset.from_tensor_slices()`를 사용했기 때문에 각 데이터셋은 차례대로 원소를 반환합니다. 다음 이 세 개의 데이터셋에서 각각 두 개의 아이템(`block_length=2`이므로)을 추출합니다. 세 개의 데이터셋의 아이템이 모두 소진될 때까지 반복됩니다. 즉 0,1 (첫 번째에서), 7,8 (두 번째에서), 4,5 (세 번째에서), 2,3 (첫 번째에서), 9,0 (두 번째에서) 등과 같은 식으로 8,9 (세 번째에서), 6 (첫 번째에서), 3 (두 번째에서), 0 (세 번째에서)까지 진행됩니다. 그다음에 원본 데이터셋에서 다음 번 세 개의 원소를 추출하려고 합니다. 하지만 두 개만 남아 있습니다. `[1,2,3,4,5,6,7]`와 `[8,9]` 입니다. 다시 이 원소로부터 데이터셋을 만들고 이 데이텃세의 아이템이 모두 소진될 때까지 두 개의 아이템을 추출합니다. 1,2 (첫 번째에서), 8,9 (두 번째에서), 3,4 (첫 번째에서), 5,6 (첫 번째에서), 7 (첫 번째에서)가 됩니다. 배열의 길이가 다르기 때문에 마지막에는 교대로 배치되지 않았습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 리더 (Reader) - 새로운 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`from_tensor_slices()`나 `from_tensor()`를 기반으로 한 원본 데이터셋을 사용하는 대신 리더 데이터셋을 사용할 수 있습니다. 복잡한 일들을 대부분 대신 처리해 줍니다(예를 들면, 스레드):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\"my_test.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TextLineDataset(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 줄을 어떻게 디코드해야 하는지는 알려 주어야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_csv_line(line):\n",
    "    x1, x2, y = tf.decode_csv(\n",
    "        line, record_defaults=[[-1.], [-1.], [-1.]])\n",
    "    X = tf.stack([x1, x2])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그다음, 이 디코딩 함수를 `map()`을 사용하여 데이터셋에 있는 각 원소에 적용할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.skip(1).map(decode_csv_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 원-샷-이터레이터를 만들어 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = dataset.make_one_shot_iterator()\n",
    "X, y = it.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -1.] 0.0\n",
      "[4. 5.] 1.0\n",
      "[7. 8.] 0.0\n",
      "완료\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while True:\n",
    "            X_val, y_val = sess.run([X, y])\n",
    "            print(X_val, y_val)\n",
    "    except tf.errors.OutOfRangeError as ex:\n",
    "        print(\"완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 연습문제 해답"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coming soon**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
